{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Today we are going to perform the simple classification of the amazon reviews' sentiment.\n",
    "\n",
    "### Please, download the dataset amazon_baby.csv."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-09T17:03:10.542344Z",
     "start_time": "2024-11-09T17:03:09.788580Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    import string\n",
    "    if isinstance(text, str):\n",
    "        translator = str.maketrans('', '', string.punctuation)\n",
    "        return text.translate(translator)\n",
    "    return text\n",
    "baby_df = pd.read_csv('./data/amazon_baby.csv')\n",
    "baby_df.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                name  \\\n",
       "0                           Planetwise Flannel Wipes   \n",
       "1                              Planetwise Wipe Pouch   \n",
       "2                Annas Dream Full Quilt with 2 Shams   \n",
       "3  Stop Pacifier Sucking without tears with Thumb...   \n",
       "4  Stop Pacifier Sucking without tears with Thumb...   \n",
       "\n",
       "                                              review  rating  \n",
       "0  These flannel wipes are OK, but in my opinion ...       3  \n",
       "1  it came early and was not disappointed. i love...       5  \n",
       "2  Very soft and comfortable and warmer than it l...       5  \n",
       "3  This is a product well worth the purchase.  I ...       5  \n",
       "4  All of my kids have cried non-stop when I trie...       5  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Planetwise Flannel Wipes</td>\n",
       "      <td>These flannel wipes are OK, but in my opinion ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Planetwise Wipe Pouch</td>\n",
       "      <td>it came early and was not disappointed. i love...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annas Dream Full Quilt with 2 Shams</td>\n",
       "      <td>Very soft and comfortable and warmer than it l...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>This is a product well worth the purchase.  I ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>All of my kids have cried non-stop when I trie...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1 (data preparation)\n",
    "a) Remove punctuation from reviews using the given function.   \n",
    "b) Replace all missing (nan) revies with empty \"\" string.  \n",
    "c) Drop all the entries with rating = 3, as they have neutral sentiment.   \n",
    "d) Set all positive ($\\geq$4) ratings to 1 and negative($\\leq$2) to -1."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-09T17:03:15.679633Z",
     "start_time": "2024-11-09T17:03:14.346751Z"
    }
   },
   "source": [
    "#a)\n",
    "\n",
    "baby_df[\"review\"] = baby_df[\"review\"].apply(remove_punctuation)\n",
    "#short test: \n",
    "baby_df[\"review\"][4] == 'All of my kids have cried nonstop when I tried to ween them off their pacifier until I found Thumbuddy To Loves Binky Fairy Puppet  It is an easy way to work with your kids to allow them to understand where their pacifier is going and help them part from itThis is a must buy book and a great gift for expecting parents  You will save them soo many headachesThanks for this book  You all rock'\n",
    "remove_punctuation(baby_df[\"review\"][4]) == 'All of my kids have cried nonstop when I tried to ween them off their pacifier until I found Thumbuddy To Loves Binky Fairy Puppet  It is an easy way to work with your kids to allow them to understand where their pacifier is going and help them part from itThis is a must buy book and a great gift for expecting parents  You will save them soo many headachesThanks for this book  You all rock'"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "I had to modify the function a bit, because it was trying to remove punctuation from a float. Now it works as expected."
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-09T17:03:15.745572Z",
     "start_time": "2024-11-09T17:03:15.693731Z"
    }
   },
   "source": [
    "#b)\n",
    "baby_df[\"review\"] = baby_df[\"review\"].fillna(\"\")\n",
    "\n",
    "#short test:\n",
    "baby_df[\"review\"][38] == baby_df[\"review\"][38]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now there are no NaN values in the dataset. We now that because the value NaN compared with other NaN could not be equal."
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-09T17:03:15.847369Z",
     "start_time": "2024-11-09T17:03:15.786480Z"
    }
   },
   "source": [
    "#c)\n",
    "baby_df = baby_df[baby_df['rating'] != 3].reset_index(drop=True)\n",
    "\n",
    "#short test:\n",
    "sum(baby_df[\"rating\"] == 3)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "There is no rating equal to 3 in the dataset as we can wee above."
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-09T17:03:16.038168Z",
     "start_time": "2024-11-09T17:03:16.009490Z"
    }
   },
   "source": [
    "#d) \n",
    "baby_df[\"rating\"] = np.where(baby_df[\"rating\"] >= 4, 1, -1)\n",
    "\n",
    "#short test:\n",
    "sum(baby_df[\"rating\"]**2 != 1)\n",
    "\n",
    "#163lk"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now we have only two classes of ratings. 1 or -1"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer\n",
    "In order to analyze strings, we need to assign them numerical values. We will use one of the simplest string representation, which transforms strings into the $n$ dimensional vectors. The number of dimensions will be the size of our dictionary, and then the values of the vector will represent the number of appereances of the given word in the sentence."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-09T17:03:16.197581Z",
     "start_time": "2024-11-09T17:03:16.191637Z"
    }
   },
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "reviews_train_example = [\"We like apples\",\n",
    "                   \"We hate oranges\",\n",
    "                   \"I adore bananas\",\n",
    "                   \"We like like apples and oranges\",\n",
    "                   \"They dislike bananas\"]\n",
    "\n",
    "X_train_example = vectorizer.fit_transform(reviews_train_example)\n",
    "\n",
    "print(vectorizer.get_feature_names_out())\n",
    "print(X_train_example.todense())\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['adore' 'and' 'apples' 'bananas' 'dislike' 'hate' 'like' 'oranges' 'they'\n",
      " 'we']\n",
      "[[0 0 1 0 0 0 1 0 0 1]\n",
      " [0 0 0 0 0 1 0 1 0 1]\n",
      " [1 0 0 1 0 0 0 0 0 0]\n",
      " [0 1 1 0 0 0 2 1 0 1]\n",
      " [0 0 0 1 1 0 0 0 1 0]]\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "I had to change the function get_feature_names() to get_feature_names_out() because of the deprecation. From certain version of sklearn, the function get_feature_names() has been replaced with get_feature_names_out().\n",
    "\n",
    "## Vectorizer: \n",
    "is a tool used in Natural Language Processing (NLP) to convert text data into numerical data. This process is essential because machine learning models cannot process raw text data directly; they require numerical input.\n",
    "## CountVectorizer:\n",
    "is a type of text vectorization technique that converts a collection of text documents (such as sentences or paragraphs) into a matrix of token counts, where each token is a word. It essentially transforms text into a bag-of-words (BoW) representation.\n",
    "## How does CountVectorizer Work?\n",
    "- **Tokenization**: It breaks down the text into individual words, known as tokens.\n",
    "- **Building the Vocabulary**: It creates a vocabulary (dictionary) of all unique words present in the dataset.\n",
    "- **Counting Word Frequencies**: For each document, it counts the occurrences of each word in the vocabulary.\n",
    "- **Creating the Matrix**: It represents the document as a sparse matrix, where:\n",
    "    - Rows correspond to each document in the dataset.\n",
    "    - Columns correspond to each unique word in the vocabulary.\n",
    "    - The values represent the frequency of the word in that specific document."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-09T17:03:16.289472Z",
     "start_time": "2024-11-09T17:03:16.285076Z"
    }
   },
   "source": [
    "reviews_test_example = [\"They like bananas\",\n",
    "                   \"We hate oranges bananas and apples\",\n",
    "                   \"We love bananas\"] #New word!\n",
    "\n",
    "X_test_example = vectorizer.transform(reviews_test_example)\n",
    "\n",
    "print(X_test_example.todense())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 1 0 0 1 0 1 0]\n",
      " [0 1 1 1 0 1 0 1 0 1]\n",
      " [0 0 0 1 0 0 0 0 0 1]]\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should acknowledge few facts. Firstly, CountVectorizer does not take order into account. Secondly, it ignores one-letter words (this can be changed during initialization). Finally, for test values, CountVectorizer ignores words which are not in it's dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 \n",
    "a) Split dataset into training and test sets.     \n",
    "b) Transform reviews into vectors using CountVectorizer. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-09T17:03:16.631189Z",
     "start_time": "2024-11-09T17:03:16.600843Z"
    }
   },
   "source": [
    "#a)\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_x, test_x, train_y, test_y = train_test_split(baby_df[\"review\"], baby_df[\"rating\"], test_size=0.2, random_state=42)\n"
   ],
   "outputs": [],
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-09T17:03:25.520785Z",
     "start_time": "2024-11-09T17:03:16.722324Z"
    }
   },
   "source": [
    "#b)\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "train_x = vectorizer.fit_transform(train_x)\n",
    "test_x = vectorizer.transform(test_x)\n"
   ],
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Using the created train_test_split I split the data from baby_df.\n",
    "Then I used CountVectorizer to transform the reviews into vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3 \n",
    "a) Train LogisticRegression model on training data (reviews processed with CountVectorizer, ratings as they were).   \n",
    "b) Print 10 most positive and 10 most negative words."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-09T17:03:48.061075Z",
     "start_time": "2024-11-09T17:03:25.545486Z"
    }
   },
   "source": [
    "#a)\n",
    "model = LogisticRegression(max_iter = 1000)\n",
    "\n",
    "model.fit(train_x, train_y)\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ],
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(max_iter=1000)</pre></div> </div></div></div></div>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-09T17:03:48.220580Z",
     "start_time": "2024-11-09T17:03:48.094512Z"
    }
   },
   "source": [
    "#b)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "coefficients = model.coef_[0]\n",
    "\n",
    "sorted_indices = np.argsort(coefficients)\n",
    "\n",
    "most_negative = [feature_names[i] for i in sorted_indices[:10]]\n",
    "most_positive = [feature_names[i] for i in sorted_indices[-10:]]\n",
    "\n",
    "print(\"Most negative words: \", most_negative)\n",
    "print(\"Most positive words: \", most_positive)\n",
    "\n",
    "\n",
    "#hint: model.coef_, vectorizer.get_feature_names()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most negative words:  ['dissapointed', 'worthless', 'worst', 'useless', 'poorly', 'disappointing', 'unusable', 'disappointed', 'unacceptable', 'poor']\n",
      "Most positive words:  ['wonderfully', 'hinder', 'saves', 'skeptical', 'rich', 'thankful', 'con', 'ply', 'minor', 'lifesaver']\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We can clearly see that the most positive and negative words are related to the sentiment of the reviews. As we look above, the words picked by our model make sense. \n",
    "I also see that some words for instance dissapointed and disappointed are the same, but the model treats them as different words because dataframe included words having spelling mistakes.\n",
    "  "
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Code below \n",
    "The cell below is used for measuring time which we have to do in the last exercise. \n",
    "It is here because it is easier to measure time of instructions in the same order and in one cell\n",
    "<br>For now, we can skip it. "
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T17:04:16.597184Z",
     "start_time": "2024-11-09T17:03:48.266887Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import datetime\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(baby_df[\"review\"], baby_df[\"rating\"], test_size=0.2, random_state=42)\n",
    "\n",
    "s_time = datetime.datetime.now()\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "train_x = vectorizer.fit_transform(train_x)\n",
    "test_x = vectorizer.transform(test_x)\n",
    "\n",
    "model = LogisticRegression(max_iter = 1000)\n",
    "model.fit(train_x, train_y)\n",
    "\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "coefficients = model.coef_[0]\n",
    "\n",
    "sorted_indices = np.argsort(coefficients)\n",
    "\n",
    "most_negative = [feature_names[i] for i in sorted_indices[:10]]\n",
    "most_positive = [feature_names[i] for i in sorted_indices[-10:]]\n",
    "\n",
    "print(\"Most negative words: \", most_negative)\n",
    "print(\"Most positive words: \", most_positive)\n",
    "\n",
    "\n",
    "predicted_sentiments = model.predict(test_x)\n",
    "predicted_sentiments_proba = model.predict_proba(test_x)\n",
    "\n",
    "e_time = datetime.datetime.now()\n",
    "unlimited_vocab_time = e_time - s_time\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most negative words:  ['dissapointed', 'worthless', 'worst', 'useless', 'poorly', 'disappointing', 'unusable', 'disappointed', 'unacceptable', 'poor']\n",
      "Most positive words:  ['wonderfully', 'hinder', 'saves', 'skeptical', 'rich', 'thankful', 'con', 'ply', 'minor', 'lifesaver']\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4 \n",
    "a) Predict the sentiment of test data reviews.   \n",
    "b) Predict the sentiment of test data reviews in terms of probability.   \n",
    "c) Find five most positive and most negative reviews.   \n",
    "d) Calculate the accuracy of predictions."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-09T17:04:16.635920Z",
     "start_time": "2024-11-09T17:04:16.623428Z"
    }
   },
   "source": [
    "#a)\n",
    "predicted_sentiments = model.predict(test_x)"
   ],
   "outputs": [],
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-09T17:04:16.666686Z",
     "start_time": "2024-11-09T17:04:16.654841Z"
    }
   },
   "source": [
    "#b)\n",
    "predicted_sentiments_proba = model.predict_proba(test_x)\n",
    "#hint: model.predict_proba()"
   ],
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## What is the difference between model.predict() and model.predict_proba()\n",
    "Those two methods are commonly used in machine learning classification models, but they serve different purposes. Here's a breakdown of their differences and when to use each.<br>\n",
    "- model.predict():\n",
    "    - purpose: used to make a prediction about the class label for each sample in your input data. It returns the most likely class based on the learned model.\n",
    "    - output: An array of class labels. Each element in the output corresponds to the predicted class for a sample.\n",
    "- model.predict_proba():   \n",
    "    - purpose: used to obtain the probability estimates for each class. It returns the probability that a given sample belongs to each possible class.\n",
    "    - output: \n",
    "        - A 2D array where each row corresponds to a sample and each column corresponds to a class.  \n",
    "        -  The values in each row are probabilities that sum to 1.0.\n",
    "## When to use each method?\n",
    "- model.predict() when: \n",
    "    - You only care about the predicted class and don't need to know the confidence level.\n",
    "    - You need a simple classification decision (e.g., spam vs. not spam).\n",
    "- model.predict_proba() when:\n",
    "    - You want to understand the model's confidence in its predictions.\n",
    "    - You need to set custom thresholds for classifying samples.\n",
    "        - For example, you may only want to classify a sample as \"positive\" if the probability is greater than 0.7."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-09T17:04:16.713442Z",
     "start_time": "2024-11-09T17:04:16.686215Z"
    }
   },
   "source": [
    "#c) #d)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"review\": baby_df[\"review\"].iloc[test_y.index],\n",
    "    \"true_rating\": test_y.values,\n",
    "    \"predicted_rating\": predicted_sentiments,\n",
    "    \"predicted_rating_proba\": predicted_sentiments_proba[:, 1]\n",
    "})\n",
    "\n",
    "most_positive = df.sort_values(\"predicted_rating_proba\", ascending=False).head(5)\n",
    "most_negative = df.sort_values(\"predicted_rating_proba\").head(5)\n",
    "accuracy_1 = np.mean(predicted_sentiments == test_y)\n",
    "\n",
    "print(f\"Most positive reviews: {most_positive}\")\n",
    "print(f\"Most negative reviews: {most_negative}\")\n",
    "print(f\"Accuracy: {accuracy_1}\")\n",
    "\n",
    "#hint: use the results of b)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most positive reviews:                                                    review  true_rating  \\\n",
      "130545  I was a little nervous about ordering this bab...            1   \n",
      "99578   My wifes 5 and Im about 56 our baby is within ...            1   \n",
      "112343  I did a TON of research before I purchased thi...            1   \n",
      "51918   I started wearing the Babyplus when I was 18 w...            1   \n",
      "164117  After much research I purchased an Urbo2 Its e...            1   \n",
      "\n",
      "        predicted_rating  predicted_rating_proba  \n",
      "130545                 1                     1.0  \n",
      "99578                  1                     1.0  \n",
      "112343                 1                     1.0  \n",
      "51918                  1                     1.0  \n",
      "164117                 1                     1.0  \n",
      "Most negative reviews:                                                    review  true_rating  \\\n",
      "134430  My disappointment with this product prompted m...           -1   \n",
      "159179  I had to return this stroller for three reason...           -1   \n",
      "81660   I am so incredibly disappointed with the strol...           -1   \n",
      "70004   I thought it sounded great to have different t...           -1   \n",
      "52029   My husband and I are VERY disappointed and sho...           -1   \n",
      "\n",
      "        predicted_rating  predicted_rating_proba  \n",
      "134430                -1            3.422797e-20  \n",
      "159179                -1            2.390867e-19  \n",
      "81660                 -1            2.836120e-16  \n",
      "70004                 -1            1.129212e-14  \n",
      "52029                 -1            4.113140e-14  \n",
      "Accuracy: 0.9326856765914066\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Results:\n",
    "- It seems like the most positive and negative review were **found correctly**. \n",
    "- **The accuracy** of the model is quite high, which is a good sign. It is **0.93**, which means that 93% of the reviews were classified correctly.\n",
    "- We also can see that the **predicted_rating_proba** is 1.0 in the 5 most positive reviews and is a very low negative value in every one of 5 most negative reviews.\n",
    "- **Predicted rating** is always -1 or 1 as expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5\n",
    "In this exercise we will limit the dictionary of CountVectorizer to the set of significant words, defined below.\n",
    "\n",
    "\n",
    "a) Redo exercises 2-5 using limited dictionary.   \n",
    "b) Check the impact of all the words from the dictionary.   \n",
    "c) Compare accuracy of predictions and the time of evaluation."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-09T17:04:16.741306Z",
     "start_time": "2024-11-09T17:04:16.737229Z"
    }
   },
   "source": [
    "significant_words = ['love','great','easy','old','little','perfect','loves','well','able','car','broke','less','even','waste','disappointed','work','product','money','would','return']"
   ],
   "outputs": [],
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-09T17:04:22.988532Z",
     "start_time": "2024-11-09T17:04:16.768820Z"
    }
   },
   "source": [
    "#a)\n",
    "import datetime\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(baby_df[\"review\"], baby_df[\"rating\"], test_size=0.2, random_state=42)\n",
    "\n",
    "s_time = datetime.datetime.now()\n",
    "\n",
    "vectorizer = CountVectorizer(vocabulary=significant_words)\n",
    "\n",
    "train_x = vectorizer.fit_transform(train_x)\n",
    "test_x = vectorizer.transform(test_x)\n",
    "\n",
    "model = LogisticRegression(max_iter = 1000)\n",
    "model.fit(train_x, train_y)\n",
    "\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "coefficients = model.coef_[0]\n",
    "\n",
    "sorted_indices = np.argsort(coefficients)\n",
    "\n",
    "most_negative = [feature_names[i] for i in sorted_indices[:10]]\n",
    "most_positive = [feature_names[i] for i in sorted_indices[-10:]]\n",
    "\n",
    "print(\"Most negative words: \", most_negative)\n",
    "print(\"Most positive words: \", most_positive)\n",
    "\n",
    "\n",
    "predicted_sentiments = model.predict(test_x)\n",
    "predicted_sentiments_proba = model.predict_proba(test_x)\n",
    "\n",
    "e_time = datetime.datetime.now()\n",
    "limited_vocab_time = e_time - s_time\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"review\": baby_df[\"review\"].iloc[test_y.index],\n",
    "    \"true_rating\": test_y.values,\n",
    "    \"predicted_rating\": predicted_sentiments,\n",
    "    \"predicted_rating_proba\": predicted_sentiments_proba[:, 1]\n",
    "})\n",
    "\n",
    "\n",
    "most_positive = df.sort_values(\"predicted_rating_proba\", ascending=False).head(5)\n",
    "most_negative = df.sort_values(\"predicted_rating_proba\").head(5)\n",
    "\n",
    "accuracy_2 = np.mean(predicted_sentiments == test_y)\n",
    "\n",
    "print(f\"Most positive reviews: {most_positive}\")\n",
    "print(f\"Most negative reviews: {most_negative}\")\n",
    "print(f\"Accuracy: {accuracy_2}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most negative words:  ['disappointed', 'return', 'waste', 'broke', 'money', 'work', 'even', 'would', 'product', 'less']\n",
      "Most positive words:  ['old', 'car', 'able', 'well', 'little', 'great', 'easy', 'love', 'perfect', 'loves']\n",
      "Most positive reviews:                                                    review  true_rating  \\\n",
      "122030  We bought this stroller after selling our belo...            1   \n",
      "68033   We love this highchair  We have a 4 year old a...            1   \n",
      "122843  Weve been using Britax for our boy now 14 mont...            1   \n",
      "137273  I did tons of research on strollers I knew I w...            1   \n",
      "66949   UPDATE 112013  I went ahead and used a tiny bi...            1   \n",
      "\n",
      "        predicted_rating  predicted_rating_proba  \n",
      "122030                 1                     1.0  \n",
      "68033                  1                     1.0  \n",
      "122843                 1                     1.0  \n",
      "137273                 1                     1.0  \n",
      "66949                  1                     1.0  \n",
      "Most negative reviews:                                                    review  true_rating  \\\n",
      "37813   Looks really cute however the cloth smells fun...           -1   \n",
      "153003  I loved all the features of the car seat  It i...            1   \n",
      "100936  I searched for Baby Blanket Made in the USA an...           -1   \n",
      "88380   I received this glider and it was broke and wo...           -1   \n",
      "40988   My wife and I were looking for a monitor for o...           -1   \n",
      "\n",
      "        predicted_rating  predicted_rating_proba  \n",
      "37813                 -1            3.985187e-08  \n",
      "153003                -1            1.931293e-06  \n",
      "100936                -1            7.762553e-05  \n",
      "88380                 -1            1.311507e-04  \n",
      "40988                 -1            4.208291e-04  \n",
      "Accuracy: 0.8689994303019399\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Comment:\n",
    "- **Accuracy**:\n",
    "    - The accuracy of the model with the limited vocabulary is **0.87** which is quite worse than the previous one with **0.93**.\n",
    "    - It can be that the model know better which words to choose in order of classification\n",
    "- **Result**:\n",
    "    - The most positive and negative reviews are different compared to the previous model's.\n",
    "    - It does not necessarily mean that the model is worse, but it is undoubtedly different.    "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-09T17:04:23.015658Z",
     "start_time": "2024-11-09T17:04:23.007140Z"
    }
   },
   "source": [
    "#b)\n",
    "\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "coefficients = model.coef_[0]\n",
    "\n",
    "word_impact = pd.DataFrame({\n",
    "    \"word\": feature_names,\n",
    "    \"impact\": coefficients\n",
    "}).sort_values(\"impact\", ascending=False)\n",
    "\n",
    "print(\"\\nWord_impact\\n\", word_impact)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Word_impact\n",
      "             word    impact\n",
      "6          loves  1.684972\n",
      "5        perfect  1.515068\n",
      "0           love  1.359000\n",
      "2           easy  1.193224\n",
      "1          great  0.930882\n",
      "4         little  0.502431\n",
      "7           well  0.496196\n",
      "8           able  0.193270\n",
      "9            car  0.074529\n",
      "3            old  0.073441\n",
      "11          less -0.201570\n",
      "16       product -0.313727\n",
      "18         would -0.342239\n",
      "12          even -0.489719\n",
      "15          work -0.635649\n",
      "17         money -0.946424\n",
      "10         broke -1.680640\n",
      "13         waste -1.979571\n",
      "19        return -2.092836\n",
      "14  disappointed -2.398751\n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## What is word_impact in our model?\n",
    "- represents the influence or importance of each word (or feature) on the predictions made by our machine learning model\n",
    "- In a linear model like Logistic Regression, each feature (word) is assigned a coefficient. These coefficients indicate the strength and direction of the impact each word has on the prediction.\n",
    "- **model.coef** is a NumPy array where each element represents the coefficient of a corresponding word\n",
    "- For binary classification, **model.coef_[0]** gives the coefficients for the first (and only) class."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-09T17:05:17.933410Z",
     "start_time": "2024-11-09T17:05:17.916721Z"
    }
   },
   "source": [
    "#c)\n",
    "print(f\"Time of evaluation without limited vocabulary (1): {unlimited_vocab_time}\")\n",
    "print(f\"Time of evaluation with limited vocabulary (2): {limited_vocab_time}\")\n",
    "print(f\"Time of evaluation difference (1-2): {abs(unlimited_vocab_time - limited_vocab_time)}\")\n",
    "\n",
    "print(f\"Accuracy without limited vocabulary (1): {accuracy_1}\")\n",
    "print(f\"Accuracy with limited vocabulary (2): {accuracy_2}\")\n",
    "print(f\"Accuracy difference (2): {abs(accuracy_2 - accuracy_1)}\")\n",
    "\n",
    "#hint: %time, %timeit"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time of evaluation without limited vocabulary (1): 0:00:28.292363\n",
      "Time of evaluation with limited vocabulary (2): 0:00:06.167744\n",
      "Time of evaluation difference (1-2): 0:00:22.124619\n",
      "Accuracy without limited vocabulary (1): 0.9326856765914066\n",
      "Accuracy with limited vocabulary (2): 0.8689994303019399\n",
      "Accuracy difference (2): 0.06368624628946662\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Comment:\n",
    "- **Time**:\n",
    "    - time of evaluation with limited vocabulary is **much shorter** than without limited vocabulary\n",
    "    - it is because the model has to process fewer words\n",
    "    - the difference is almost 19 seconds which is significant\n",
    "## Conclusion:\n",
    "- There is no golden mean here. Sometimes using limited vocabulary is more efficient.\n",
    "- From our situation I can see that the model with the limited vocabulary is less accurate but much faster which is a trade-off. "
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T17:05:12.791981Z",
     "start_time": "2024-11-09T17:05:12.777087Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
